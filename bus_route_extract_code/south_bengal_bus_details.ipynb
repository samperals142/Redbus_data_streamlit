{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1c0ac0-e88c-4e5a-9c78-db94dcfc4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile\"\n",
    "\n",
    "def init_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape all bus routes\n",
    "def scrap_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape each bus details\n",
    "def scrap_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allowing the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(8)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(6)  # Wait for the page to load more content\n",
    "\n",
    "            # extract bus items details\n",
    "            bus_name_item = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_item = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_item = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "            duration_item = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "            reaching_time_item = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_item = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_item = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "\n",
    "            # Using XPath to handle both seat availability classes\n",
    "            seat_availability_item = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_item)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_item[i].text,\n",
    "                    \"Bus_Type\": bus_type_item[i].text,\n",
    "                    \"Departing_Time\": departing_time_item[i].text,\n",
    "                    \"Duration\": duration_item[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_item[i].text,\n",
    "                    \"Star_Rating\": star_rating_item[i].text if i < len(star_rating_item) else '0',\n",
    "                    \"Price\": price_item[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_item[i].text if i < len(seat_availability_item) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrap_all_pages(driver):\n",
    "    for page in range(1, 6):  # There are 5 pages\n",
    "        try:\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrap_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrap_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# Main execution block\n",
    "try:\n",
    "    # Initialize driver once\n",
    "    driver = init_driver()\n",
    "    \n",
    "    # Scrape routes and details from all pages\n",
    "    scrap_all_pages(driver)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('sbstc_bus_details.csv', index=False)\n",
    "\n",
    "finally:\n",
    "    # Close the driver once scraping is complete\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0f1d2-c0e6-48a4-9061-4c4416ad8feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
